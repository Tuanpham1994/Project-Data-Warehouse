{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (1.9.7)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.7 in /opt/conda/lib/python3.6/site-packages (from boto3) (1.12.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3) (0.9.3)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /opt/conda/lib/python3.6/site-packages (from boto3) (0.1.13)\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.7->boto3) (0.14)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.20 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.7->boto3) (1.22)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.7->boto3) (2.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.13.0,>=1.12.7->boto3) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_CLUSTER_TYPE</td>\n",
       "      <td>multi-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_NUM_NODES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_CLUSTER_IDENTIFIER</td>\n",
       "      <td>dwhCluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_DB</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DWH_DB_USER</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DWH_DB_PASSWORD</td>\n",
       "      <td>Passw0rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DWH_PORT</td>\n",
       "      <td>5440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DWH_IAM_ROLE_NAME</td>\n",
       "      <td>dwhRole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Param       Value\n",
       "0  DWH_CLUSTER_TYPE        multi-node\n",
       "1  DWH_NUM_NODES           4         \n",
       "2  DWH_NODE_TYPE           dc2.large \n",
       "3  DWH_CLUSTER_IDENTIFIER  dwhCluster\n",
       "4  DWH_DB                  dwh       \n",
       "5  DWH_DB_USER             dwhuser   \n",
       "6  DWH_DB_PASSWORD         Passw0rd  \n",
       "7  DWH_PORT                5440      \n",
       "8  DWH_IAM_ROLE_NAME       dwhRole   "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "\n",
    "DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")\n",
    "\n",
    "(DWH_DB_USER, DWH_DB_PASSWORD, DWH_DB)\n",
    "\n",
    "pd.DataFrame({\"Param\":\n",
    "                  [\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\", \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\", \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\"],\n",
    "              \"Value\":\n",
    "                  [DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME]\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create clients for EC2, S3, IAM, and Redshift\n",
    "import boto3\n",
    "ec2 = boto3.resource('ec2',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                    )\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                   )\n",
    "\n",
    "iam = boto3.client('iam',aws_access_key_id=KEY,\n",
    "                     aws_secret_access_key=SECRET,\n",
    "                     region_name='us-west-2'\n",
    "                  )\n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/customer0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/dwdate.tbl.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0001_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0003_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0004_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0005_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0006_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0007_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0001_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0003_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier.tbl_0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier0001_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier0003_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw-manifest')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-000')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-000.bak')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-001')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-002')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-003')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-004')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-005')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-006')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-007')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl.log')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-000')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-001')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-002')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-003')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-004')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-005')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-006')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-007')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/lo/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/lo/lineorder-multi.tbl0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='nested_example/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='nested_example/customers/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='nested_example/customers/customer_file1')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='resize/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='resize/etl_category_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='resize/etl_date_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='resize/etl_events_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='resize/etl_venue_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='resize/listings_pipe_1.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0001_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0003_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0004_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0005_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0006_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0007_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0008_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0009_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0010_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0011_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0012_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0013_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0014_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0015_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/results.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/customer0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/dwdate.tbl.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0001_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0003_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0004_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0005_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0006_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0007_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0001_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0003_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier.tbl_0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier0001_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier0003_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/allevents_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/allusers_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/category_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/date2008_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/listings_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/sales_tab.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/category/category_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/date/date2008_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/event/allevents_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/listing/listings_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales/sales_ts.000')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-01/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-01/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-01/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-01/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-01/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-01/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-02/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-02/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-02/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-02/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-02/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-02/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-03/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-03/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-03/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-03/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-03/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-03/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-04/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-04/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-04/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-04/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-04/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-04/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-05/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-05/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-05/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-05/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-05/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-05/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-06/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-06/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-06/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-06/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-06/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-06/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-07/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-07/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-07/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-07/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-07/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-07/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-08/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-08/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-08/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-08/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-08/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-08/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-09/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-09/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-09/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-09/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-09/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-09/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-10/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-10/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-10/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-10/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-10/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-10/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-11/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-11/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-11/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-11/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-11/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-11/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-12/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-12/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-12/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-12/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-12/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-12/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-01/event=101/000')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-01/event=102/000')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-01/event=103/000')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-02/event=101/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-02/event=101/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-02/event=102/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-02/event=102/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-02/event=103/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-02/event=103/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-03/event=101/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-03/event=101/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-03/event=102/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-03/event=102/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-03/event=103/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-03/event=103/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/users/allusers_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/venue/venue_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/svl_s3query.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/venue_pipe.txt')\n"
     ]
    }
   ],
   "source": [
    "#Check out sample bucket\n",
    "sampleDbBucket =  s3.Bucket(\"awssampledbuswest2\")\n",
    "for obj in sampleDbBucket.objects.filter(Prefix=\"ssbgz\"):\n",
    "    print(obj)\n",
    "for obj in sampleDbBucket.objects.all():\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name dwhRole already exists.\n",
      "1.2 Attaching Policy\n",
      "1.3 Get the IAM role ARN\n",
      "arn:aws:iam::349342746091:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "#Create IAM role\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#1.1 Create the role, \n",
    "try:\n",
    "    print(\"1.1 Creating a new IAM Role\") \n",
    "    dwhRole = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=DWH_IAM_ROLE_NAME,\n",
    "        Description = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "             'Version': '2012-10-17'})\n",
    "    )    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "print(\"1.2 Attaching Policy\")\n",
    "\n",
    "iam.attach_role_policy(RoleName=DWH_IAM_ROLE_NAME,\n",
    "                       PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "print(\"1.3 Get the IAM role ARN\")\n",
    "roleArn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "print(roleArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred (ClusterAlreadyExists) when calling the CreateCluster operation: Cluster already exists\n"
     ]
    }
   ],
   "source": [
    "#Create Redshift cluster\n",
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        #HW\n",
    "        ClusterType=DWH_CLUSTER_TYPE,\n",
    "        NodeType=DWH_NODE_TYPE,\n",
    "        NumberOfNodes=int(DWH_NUM_NODES),\n",
    "\n",
    "        #Identifiers & Credentials\n",
    "        DBName=DWH_DB,\n",
    "        ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername=DWH_DB_USER,\n",
    "        MasterUserPassword=DWH_DB_PASSWORD,\n",
    "        \n",
    "        #Roles (for s3 access)\n",
    "        IamRoles=[roleArn]  \n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.c6fyau36ghdo.us-west-2.redshift.amazonaws.com', 'Port': 5440}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-078563cfe838c4901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  available                                                                              \n",
       "3  dwhuser                                                                                \n",
       "4  dwh                                                                                    \n",
       "5  {'Address': 'dwhcluster.c6fyau36ghdo.us-west-2.redshift.amazonaws.com', 'Port': 5440}  \n",
       "6  vpc-078563cfe838c4901                                                                  \n",
       "7  4                                                                                      "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWH_ENDPOINT ::  dwhcluster.c6fyau36ghdo.us-west-2.redshift.amazonaws.com\n",
      "DWH_ROLE_ARN ::  arn:aws:iam::349342746091:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "#Do not run this below code until the Cluster status become available\n",
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "print(\"DWH_ENDPOINT :: \", DWH_ENDPOINT)\n",
    "print(\"DWH_ROLE_ARN :: \", DWH_ROLE_ARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-0fc2e48a6a6241853')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5440, to port: 5440, ALLOW\" already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName=defaultSg.group_name,\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP',\n",
    "        FromPort=int(DWH_PORT),\n",
    "        ToPort=int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-sql in /opt/conda/lib/python3.6/site-packages (0.3.9)\n",
      "Requirement already satisfied: sqlparse in /opt/conda/lib/python3.6/site-packages (from ipython-sql) (0.3.0)\n",
      "Requirement already satisfied: sqlalchemy>=0.6.7 in /opt/conda/lib/python3.6/site-packages (from ipython-sql) (1.1.13)\n",
      "Requirement already satisfied: ipython-genutils>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: ipython>=1.0 in /opt/conda/lib/python3.6/site-packages (from ipython-sql) (6.5.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from ipython-sql) (1.11.0)\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.6/site-packages (from ipython-sql) (0.7.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (4.0.11)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (0.10.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (0.1.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /opt/conda/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (0.8.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (4.3.2)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (2.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (38.4.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (4.3.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /opt/conda/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (1.0.15)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (0.7.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=1.0->ipython-sql) (0.5.2)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython>=1.0->ipython-sql) (0.1.7)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.6/site-packages (1.1.13)\n"
     ]
    }
   ],
   "source": [
    "#Connect with cluster\n",
    "!pip install ipython-sql\n",
    "!pip install sqlalchemy \n",
    "%reload_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://dwhuser:Passw0rd@dwhcluster.c6fyau36ghdo.us-west-2.redshift.amazonaws.com:5440/dwh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: dwhuser@dwh'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT,DWH_DB)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the table\n",
    "\n",
    "import configparser\n",
    "\n",
    "# CONFIG\n",
    "config = configparser.ConfigParser()\n",
    "# Read the dwh configuration\n",
    "config.read('dwh.cfg')\n",
    "\n",
    "# DROP TABLES\n",
    "\n",
    "staging_events_table_drop = \"DROP TABLE IF EXISTS stagingevents_tab;\"\n",
    "staging_songs_table_drop = \"DROP TABLE IF EXISTS stagingsongs_tab;\"\n",
    "songplay_table_drop = \"DROP TABLE IF EXISTS songplays_tab;\"\n",
    "user_table_drop = \"DROP TABLE IF EXISTS users_tab;\"\n",
    "song_table_drop = \"DROP TABLE IF EXISTS songs_tab;\"\n",
    "artist_table_drop = \"DROP TABLE IF EXISTS artists_tab;\"\n",
    "time_table_drop = \"DROP TABLE IF EXISTS time_tab;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dwh configuration\n",
    "\n",
    "ARN             = config.get('IAM_ROLE', 'ARN')\n",
    "LOG_DATA        = config.get('S3', 'LOG_DATA')\n",
    "LOG_JSONPATH    = config.get('S3', 'LOG_JSONPATH')\n",
    "SONG_DATA       = config.get('S3', 'SONG_DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TABLES\n",
    "\n",
    "staging_events_table_create= (\"\"\"CREATE TABLE IF NOT EXISTS stagingevents_tab (\n",
    "                event_id    BIGINT IDENTITY(0,1)    NOT NULL,\n",
    "                artist      VARCHAR                 NULL,\n",
    "                auth        VARCHAR                 NULL,\n",
    "                firstName   VARCHAR                 NULL,\n",
    "                gender      VARCHAR                 NULL,\n",
    "                itemInSession VARCHAR               NULL,\n",
    "                lastName    VARCHAR                 NULL,\n",
    "                length      VARCHAR                 NULL,\n",
    "                level       VARCHAR                 NULL,\n",
    "                location    VARCHAR                 NULL,\n",
    "                method      VARCHAR                 NULL,\n",
    "                page        VARCHAR                 NULL,\n",
    "                registration VARCHAR                NULL,\n",
    "                sessionId   INTEGER                 NOT NULL SORTKEY DISTKEY,\n",
    "                song        VARCHAR                 NULL,\n",
    "                status      INTEGER                 NULL,\n",
    "                ts          BIGINT                  NOT NULL,\n",
    "                userAgent   VARCHAR                 NULL,\n",
    "                userId      INTEGER                 NULL);\n",
    "\"\"\")\n",
    "\n",
    "staging_songs_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS stagingsongs_tab (\n",
    "                num_songs           INTEGER         NULL,\n",
    "                artist_id           VARCHAR         NOT NULL SORTKEY DISTKEY,\n",
    "                artist_latitude     VARCHAR         NULL,\n",
    "                artist_longitude    VARCHAR         NULL,\n",
    "                artist_location     VARCHAR(500)   NULL,\n",
    "                artist_name         VARCHAR(500)   NULL,\n",
    "                song_id             VARCHAR         NOT NULL,\n",
    "                title               VARCHAR(500)   NULL,\n",
    "                duration            DECIMAL(9)      NULL,\n",
    "                year                INTEGER         NULL);\n",
    "\"\"\")\n",
    "\n",
    "songplay_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS songplays_tab (\n",
    "                songplay_id INTEGER IDENTITY(0,1)   NOT NULL SORTKEY,\n",
    "                start_time  TIMESTAMP               NOT NULL,\n",
    "                user_id     VARCHAR(50)             NOT NULL DISTKEY,\n",
    "                level       VARCHAR(10)             NOT NULL,\n",
    "                song_id     VARCHAR(40)             NOT NULL,\n",
    "                artist_id   VARCHAR(50)             NOT NULL,\n",
    "                session_id  VARCHAR(50)             NOT NULL,\n",
    "                location    VARCHAR(100)            NULL,\n",
    "                user_agent  VARCHAR(255)            NULL\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "user_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS users_tab (\n",
    "                user_id     INTEGER                 NOT NULL SORTKEY,\n",
    "                first_name  VARCHAR(50)             NULL,\n",
    "                last_name   VARCHAR(80)             NULL,\n",
    "                gender      VARCHAR(10)             NULL,\n",
    "                level       VARCHAR(10)             NULL\n",
    "    ) diststyle all;\n",
    "\"\"\")\n",
    "\n",
    "song_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS songs_tab (\n",
    "                song_id     VARCHAR(50)             NOT NULL SORTKEY,\n",
    "                title       VARCHAR(500)           NOT NULL,\n",
    "                artist_id   VARCHAR(50)             NOT NULL,\n",
    "                year        INTEGER                 NOT NULL,\n",
    "                duration    DECIMAL(9)              NOT NULL\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "artist_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS artists_tab (\n",
    "                artist_id   VARCHAR(50)             NOT NULL SORTKEY,\n",
    "                name        VARCHAR(500)           NULL,\n",
    "                location    VARCHAR(500)           NULL,\n",
    "                latitude    DECIMAL(9)              NULL,\n",
    "                longitude   DECIMAL(9)              NULL\n",
    "    ) diststyle all;\n",
    "\"\"\")\n",
    "\n",
    "time_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS time_tab (\n",
    "                start_time  TIMESTAMP               NOT NULL SORTKEY,\n",
    "                hour        SMALLINT                NULL,\n",
    "                day         SMALLINT                NULL,\n",
    "                week        SMALLINT                NULL,\n",
    "                month       SMALLINT                NULL,\n",
    "                year        SMALLINT                NULL,\n",
    "                weekday     SMALLINT                NULL\n",
    "    ) diststyle all;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGING TABLES\n",
    "\n",
    "staging_events_copy = (\"\"\"COPY stagingevents_tab FROM {}\n",
    "    credentials 'aws_iam_role={}'\n",
    "    format as json {}\n",
    "    STATUPDATE ON\n",
    "    region 'us-west-2';\n",
    "\"\"\").format(LOG_DATA, ARN, LOG_JSONPATH)\n",
    "\n",
    "staging_songs_copy = (\"\"\"COPY stagingsongs_tab FROM {}\n",
    "    credentials 'aws_iam_role={}'\n",
    "    format as json 'auto'\n",
    "    ACCEPTINVCHARS AS '^'\n",
    "    STATUPDATE ON\n",
    "    region 'us-west-2';\n",
    "\"\"\").format(SONG_DATA,ARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL TABLES\n",
    "\n",
    "songplay_table_insert = (\"\"\"INSERT INTO songplays_tab (start_time,\n",
    "                                        user_id,\n",
    "                                        level,\n",
    "                                        song_id,\n",
    "                                        artist_id,\n",
    "                                        session_id,\n",
    "                                        location,\n",
    "                                        user_agent) SELECT  DISTINCT TIMESTAMP 'epoch' + se.ts/1000 \\\n",
    "                * INTERVAL '1 second'   AS start_time,\n",
    "            se.userId                   AS user_id,\n",
    "            se.level                    AS level,\n",
    "            ss.song_id                  AS song_id,\n",
    "            ss.artist_id                AS artist_id,\n",
    "            se.sessionId                AS session_id,\n",
    "            se.location                 AS location,\n",
    "            se.userAgent                AS user_agent\n",
    "    FROM stagingevents_tab AS se\n",
    "    JOIN stagingsongs_tab AS ss\n",
    "        ON (se.artist = ss.artist_name)\n",
    "    WHERE se.page = 'NextSong';\n",
    "\"\"\")\n",
    "\n",
    "user_table_insert = (\"\"\"INSERT INTO users_tab (user_id,\n",
    "                                        first_name,\n",
    "                                        last_name,\n",
    "                                        gender,\n",
    "                                        level)\n",
    "    SELECT  DISTINCT se.userId          AS user_id,\n",
    "            se.firstName                AS first_name,\n",
    "            se.lastName                 AS last_name,\n",
    "            se.gender                   AS gender,\n",
    "            se.level                    AS level\n",
    "    FROM stagingevents_tab AS se\n",
    "    WHERE se.page = 'NextSong';\n",
    "\"\"\")\n",
    "\n",
    "song_table_insert = (\"\"\"INSERT INTO songs_tab (song_id,\n",
    "                                        title,\n",
    "                                        artist_id,\n",
    "                                        year,\n",
    "                                        duration)\n",
    "    SELECT  DISTINCT ss.song_id         AS song_id,\n",
    "            ss.title                    AS title,\n",
    "            ss.artist_id                AS artist_id,\n",
    "            ss.year                     AS year,\n",
    "            ss.duration                 AS duration\n",
    "    FROM stagingsongs_tab AS ss;\n",
    "\"\"\")\n",
    "\n",
    "artist_table_insert = (\"\"\"INSERT INTO artists_tab (artist_id,\n",
    "                                        name,\n",
    "                                        location,\n",
    "                                        latitude,\n",
    "                                        longitude)\n",
    "    SELECT  DISTINCT ss.artist_id       AS artist_id,\n",
    "            ss.artist_name              AS name,\n",
    "            ss.artist_location          AS location,\n",
    "            ss.artist_latitude          AS latitude,\n",
    "            ss.artist_longitude         AS longitude\n",
    "    FROM stagingsongs_tab AS ss;\n",
    "\"\"\")\n",
    "\n",
    "time_table_insert = (\"\"\"INSERT INTO time_tab (start_time,\n",
    "                                        hour,\n",
    "                                        day,\n",
    "                                        week,\n",
    "                                        month,\n",
    "                                        year,\n",
    "                                        weekday)\n",
    "    SELECT  DISTINCT TIMESTAMP 'epoch' + se.ts/1000 \\\n",
    "                * INTERVAL '1 second'        AS start_time,\n",
    "            EXTRACT(hour FROM start_time)    AS hour,\n",
    "            EXTRACT(day FROM start_time)     AS day,\n",
    "            EXTRACT(week FROM start_time)    AS week,\n",
    "            EXTRACT(month FROM start_time)   AS month,\n",
    "            EXTRACT(year FROM start_time)    AS year,\n",
    "            EXTRACT(week FROM start_time)    AS weekday\n",
    "    FROM    stagingevents_tab                AS se\n",
    "    WHERE se.page = 'NextSong';\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUERY LISTS\n",
    "\n",
    "create_table_queries = [staging_events_table_create, staging_songs_table_create, songplay_table_create, user_table_create, song_table_create, artist_table_create, time_table_create]\n",
    "drop_table_queries = [staging_events_table_drop, staging_songs_table_drop, songplay_table_drop, user_table_drop, song_table_drop, artist_table_drop, time_table_drop]\n",
    "copy_table_queries = [staging_events_copy, staging_songs_copy]\n",
    "insert_table_queries = [songplay_table_insert, user_table_insert, song_table_insert, artist_table_insert, time_table_insert]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting configparser\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/af/0e28626b47c84172a112397f034bb1b6349960ca6e0fe7c96666e0ccae69/configparser-5.2.0-py3-none-any.whl\n",
      "Installing collected packages: configparser\n",
      "Successfully installed configparser-5.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install configparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in /opt/conda/lib/python3.6/site-packages (2.7.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import psycopg2\n",
    "from sql_queries import create_table_queries, drop_table_queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting config\n",
      "  Downloading https://files.pythonhosted.org/packages/59/3c/0dba475f1833b475e292d7c6b19464a206a18498979c2d5bfb37ca5ed27c/config-0.5.1-py2.py3-none-any.whl\n",
      "Installing collected packages: config\n",
      "Successfully installed config-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_tables(cur, conn):\n",
    "    \"\"\"The function executes the queries to drop any tables if it exist before.\"\"\"\n",
    "    for query in drop_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "def create_tables(cur, conn):\n",
    "    \"\"\"The function executes the queries to create new tables.\"\"\"\n",
    "    for query in create_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"The function connect cluster\"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('dwh.cfg')\n",
    "\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    drop_tables(cur, conn)\n",
    "    create_tables(cur, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import psycopg2\n",
    "from sql_queries import copy_table_queries, insert_table_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run etl\n",
    "def load_staging_tables(cur, conn):\n",
    "    \"\"\"Create function to load staging table query\"\"\"\n",
    "    for query in copy_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to insert table query\n",
    "def insert_tables(cur, conn):\n",
    "    \"\"\"function to insert table query\"\"\"\n",
    "    for query in insert_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "S3ServiceException:The S3 bucket addressed by the query is in a different region from this cluster.,Status 301,Error PermanentRedirect,Rid BT6K03JYARW97MFQ,ExtRid NQmSas6de+LgJ0qLQt2cVy7BawYFA9cB1dWJNH0Jsaj45EjaojfQ8RRcX2F7YRxSsQAabdIl3IQ=,CanRetry 1\nDETAIL:  \n  -----------------------------------------------\n  error:  S3ServiceException:The S3 bucket addressed by the query is in a different region from this cluster.,Status 301,Error PermanentRedirect,Rid BT6K03JYARW97MFQ,ExtRid NQmSas6de+LgJ0qLQt2cVy7BawYFA9cB1dWJNH0Jsaj45EjaojfQ8RRcX2F7YRxSsQAabdIl3IQ=,CanRetry 1\n  code:      8001\n  context:   Listing bucket=udacity-dend prefix=log_data\n  query:     201918\n  location:  s3_utility.cpp:690\n  process:   padbmaster [pid=1073979746]\n  -----------------------------------------------\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-67512ce48f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-67512ce48f51>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mload_staging_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0minsert_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-a3b7e50fd856>\u001b[0m in \u001b[0;36mload_staging_tables\u001b[0;34m(cur, conn)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"\"\"Create function to load staging table query\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcopy_table_queries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: S3ServiceException:The S3 bucket addressed by the query is in a different region from this cluster.,Status 301,Error PermanentRedirect,Rid BT6K03JYARW97MFQ,ExtRid NQmSas6de+LgJ0qLQt2cVy7BawYFA9cB1dWJNH0Jsaj45EjaojfQ8RRcX2F7YRxSsQAabdIl3IQ=,CanRetry 1\nDETAIL:  \n  -----------------------------------------------\n  error:  S3ServiceException:The S3 bucket addressed by the query is in a different region from this cluster.,Status 301,Error PermanentRedirect,Rid BT6K03JYARW97MFQ,ExtRid NQmSas6de+LgJ0qLQt2cVy7BawYFA9cB1dWJNH0Jsaj45EjaojfQ8RRcX2F7YRxSsQAabdIl3IQ=,CanRetry 1\n  code:      8001\n  context:   Listing bucket=udacity-dend prefix=log_data\n  query:     201918\n  location:  s3_utility.cpp:690\n  process:   padbmaster [pid=1073979746]\n  -----------------------------------------------\n\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"function to connect with cluster\"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('dwh.cfg')\n",
    "\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    load_staging_tables(cur, conn)\n",
    "    insert_tables(cur, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoOptionError",
     "evalue": "No option 'region' in section: 'AWS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/configparser.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, section, option, raw, vars, fallback)\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# support subclasses that define __missing__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36m__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'region'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNoOptionError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-c46b8f3059f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get the region from the configuration file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mregion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AWS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'REGION'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Verify the region of the S3 bucket for LOG_DATA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlog_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'S3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LOG_DATA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/configparser.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, section, option, raw, vars, fallback)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_UNSET\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNoOptionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoOptionError\u001b[0m: No option 'region' in section: 'AWS'"
     ]
    }
   ],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "redshift.delete_cluster( ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)\n",
    "#### CAREFUL!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "iam.detach_role_policy(RoleName=DWH_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=DWH_IAM_ROLE_NAME)\n",
    "#### CAREFUL!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
